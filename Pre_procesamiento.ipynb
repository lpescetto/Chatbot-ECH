{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhoISD4Nhx4n"
      },
      "outputs": [],
      "source": [
        "!pip install python-dotenv openai==1.13.3 langchain -U langchain-community tiktoken fastparquet -qqq\n",
        "!pip install pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import fitz\n",
        "from openai import AzureOpenAI\n",
        "import requests\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "import os"
      ],
      "metadata": {
        "id": "FWbhUrDWieRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "azure_openai_api_version = os.getenv('AZURE_OPENAI_API_VERSION')\n",
        "azure_openai_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
        "azure_openai_key = os.getenv('AZURE_OPENAI_KEY')\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    api_version=azure_openai_api_version,\n",
        "    azure_endpoint=azure_openai_endpoint,\n",
        "    api_key=azure_openai_key\n",
        ")"
      ],
      "metadata": {
        "id": "gDVHenCKi4Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Cargar el archivo JSON\n",
        "file_path = 'json_ech.json'\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Extraer la información de las variables\n",
        "variables_info = []\n",
        "for variable in data['codeBook']['dataDscr']['var']:\n",
        "    # ID para cada pregunta\n",
        "    ID = variable.get(\"_ID\")\n",
        "\n",
        "    # nombre de las variables\n",
        "    var_name = variable.get('_name', 'N/A')\n",
        "\n",
        "    # Verificar si existe la pregunta y manejar los diferentes tipos (str o dict)\n",
        "    var_question = variable.get('qstn', {}).get('qstnLit', 'No question text')\n",
        "    if isinstance(var_question, dict):  # Si es un diccionario, intentamos extraer el texto\n",
        "        var_question = var_question.get('__cdata', 'No question text')\n",
        "\n",
        "    # Guardar la información de la variable\n",
        "    var_info = {\n",
        "        'ID': ID,\n",
        "        'Variable Name': var_name,\n",
        "        'Question': var_question\n",
        "    }\n",
        "    variables_info.append(var_info)\n",
        "\n",
        "# Extraemos las preguntas/variables\n",
        "Question = [item['Question'] for item in variables_info]\n",
        "\n",
        "# Generamos embeddings para las preguntas/variables\n",
        "content_response = client.embeddings.create(\n",
        "    input=Question,\n",
        "    model=\"text-embedding-3-small\",\n",
        "    dimensions=1536\n",
        ")\n",
        "content_embeddings = [item.embedding for item in content_response.data]\n",
        "\n",
        "# Asignamos los embeddings a cada elemento\n",
        "for i, item in enumerate(data):\n",
        "    item['Question_vector'] = content_embeddings[i]\n",
        "\n",
        "with open('variables_ech_emb.json', 'w', encoding='utf-8') as outfile:\n",
        "    json.dump(data, outfile, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "c5B3mFC_jdvZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}